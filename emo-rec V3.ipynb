{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-15T05:58:20.273817Z",
     "iopub.status.busy": "2025-06-15T05:58:20.273553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 05:58:22.818958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749967102.983950      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749967103.032855      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file paths...\n",
      "\n",
      "Rebalancing datasets to address performance disparity...\n",
      "Processing training data (with augmentation)...\n",
      "\n",
      "Processing testing data (no augmentation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749967361.103072      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1749967361.103695      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1749967376.231419      35 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1749967377.895721     123 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1749967378.534418     125 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - accuracy: nan - loss: nan   \n",
      "Epoch 1: val_accuracy improved from -inf to 0.13435, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 828ms/step - accuracy: nan - loss: nan - val_accuracy: 0.1344 - val_loss: 7.2400 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - accuracy: nan - loss: nan   \n",
      "Epoch 2: val_accuracy improved from 0.13435 to 0.13650, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 791ms/step - accuracy: nan - loss: nan - val_accuracy: 0.1365 - val_loss: 8.1752 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - accuracy: nan - loss: nan \n",
      "Epoch 3: val_accuracy did not improve from 0.13650\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 796ms/step - accuracy: nan - loss: nan - val_accuracy: 0.1033 - val_loss: 10.5510 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - accuracy: nan - loss: nan \n",
      "Epoch 4: val_accuracy did not improve from 0.13650\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 782ms/step - accuracy: nan - loss: nan - val_accuracy: 0.1344 - val_loss: 10.8483 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - accuracy: nan - loss: nan \n",
      "Epoch 5: val_accuracy did not improve from 0.13650\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 798ms/step - accuracy: nan - loss: nan - val_accuracy: 0.1344 - val_loss: 8.6079 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: nan - loss: nan \n",
      "Epoch 6: val_accuracy improved from 0.13650 to 0.33137, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 784ms/step - accuracy: nan - loss: nan - val_accuracy: 0.3314 - val_loss: 4.5173 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: nan - loss: nan \n",
      "Epoch 7: val_accuracy did not improve from 0.33137\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 786ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2154 - val_loss: 4.2405 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: nan - loss: nan\n",
      "Epoch 8: val_accuracy did not improve from 0.33137\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 787ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2493 - val_loss: 3.9969 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - accuracy: nan - loss: nan\n",
      "Epoch 9: val_accuracy did not improve from 0.33137\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 789ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2065 - val_loss: 4.3841 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775ms/step - accuracy: nan - loss: nan\n",
      "Epoch 10: val_accuracy did not improve from 0.33137\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 791ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2907 - val_loss: 3.6259 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765ms/step - accuracy: nan - loss: nan\n",
      "Epoch 11: val_accuracy did not improve from 0.33137\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 785ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2827 - val_loss: 3.8337 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: nan - loss: nan\n",
      "Epoch 12: val_accuracy improved from 0.33137 to 0.51938, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 789ms/step - accuracy: nan - loss: nan - val_accuracy: 0.5194 - val_loss: 2.3978 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: nan - loss: nan\n",
      "Epoch 13: val_accuracy improved from 0.51938 to 0.71376, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 780ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7138 - val_loss: 1.7304 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: nan - loss: nan \n",
      "Epoch 14: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 775ms/step - accuracy: nan - loss: nan - val_accuracy: 0.4013 - val_loss: 2.4078 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765ms/step - accuracy: nan - loss: nan \n",
      "Epoch 15: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 782ms/step - accuracy: nan - loss: nan - val_accuracy: 0.2875 - val_loss: 3.0331 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: nan - loss: nan \n",
      "Epoch 16: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 768ms/step - accuracy: nan - loss: nan - val_accuracy: 0.3519 - val_loss: 3.2002 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769ms/step - accuracy: nan - loss: nan \n",
      "Epoch 17: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 788ms/step - accuracy: nan - loss: nan - val_accuracy: 0.4348 - val_loss: 2.1598 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: nan - loss: nan \n",
      "Epoch 18: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6908 - val_loss: 1.4655 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: nan - loss: nan \n",
      "Epoch 19: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.4311 - val_loss: 2.1252 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: nan - loss: nan \n",
      "Epoch 20: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 785ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6246 - val_loss: 1.3887 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: nan - loss: nan \n",
      "Epoch 21: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 772ms/step - accuracy: nan - loss: nan - val_accuracy: 0.5894 - val_loss: 1.4426 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765ms/step - accuracy: nan - loss: nan \n",
      "Epoch 22: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 781ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6137 - val_loss: 1.5484 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 23: val_accuracy did not improve from 0.71376\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 775ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6298 - val_loss: 1.5614 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 24: val_accuracy improved from 0.71376 to 0.73136, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7314 - val_loss: 1.2147 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 25: val_accuracy did not improve from 0.73136\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 773ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6795 - val_loss: 1.3336 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 26: val_accuracy did not improve from 0.73136\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 774ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6263 - val_loss: 1.5661 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 27: val_accuracy improved from 0.73136 to 0.78397, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 784ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7840 - val_loss: 0.9507 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 28: val_accuracy did not improve from 0.78397\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 783ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6960 - val_loss: 1.2093 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 29: val_accuracy improved from 0.78397 to 0.78765, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7877 - val_loss: 1.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 30: val_accuracy did not improve from 0.78765\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 768ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7334 - val_loss: 1.1927 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 31: val_accuracy did not improve from 0.78765\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7531 - val_loss: 1.1612 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 32: val_accuracy improved from 0.78765 to 0.78796, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 779ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7880 - val_loss: 1.0113 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 33: val_accuracy did not improve from 0.78796\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 774ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6680 - val_loss: 1.4912 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 34: val_accuracy did not improve from 0.78796\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 769ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7085 - val_loss: 1.3714 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.78796\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 775ms/step - accuracy: nan - loss: nan - val_accuracy: 0.6340 - val_loss: 1.6232 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 36: val_accuracy improved from 0.78796 to 0.83683, saving model to best_model_balanced.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 778ms/step - accuracy: nan - loss: nan - val_accuracy: 0.8368 - val_loss: 0.9361 - learning_rate: 2.5000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: nan - loss: nan  \n",
      "Epoch 37: val_accuracy did not improve from 0.83683\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 763ms/step - accuracy: nan - loss: nan - val_accuracy: 0.7911 - val_loss: 1.0272 - learning_rate: 2.5000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m  2/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 718ms/step - accuracy: 0.9323 - loss: 0.5742"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import librosa\n",
    "\n",
    "ravdess_emotion_map = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}\n",
    "tess_emotion_map = {\n",
    "    'neutral': 'neutral', 'happy': 'happy', 'sad': 'sad', 'angry': 'angry',\n",
    "    'fear': 'fearful', 'disgust': 'disgust', 'ps': 'surprised'\n",
    "}\n",
    "\n",
    "ravdess_root_dir = \"/kaggle/input/audio-data\"\n",
    "tess_root_dir = \"/kaggle/input/toronto-emotional-speech-set-tess\"\n",
    "\n",
    "print(\"Processing file paths...\")\n",
    "all_data = []\n",
    "\n",
    "if os.path.exists(ravdess_root_dir):\n",
    "    for subdir, _, files in os.walk(ravdess_root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    emotion_code = file.split(\"-\")[2]\n",
    "                    emotion = ravdess_emotion_map[emotion_code]\n",
    "                    filepath = os.path.join(subdir, file)\n",
    "                    all_data.append((filepath, emotion, 'RAVDESS'))\n",
    "                except (KeyError, IndexError):\n",
    "                    continue\n",
    "else:\n",
    "    print(f\"Warning: RAVDESS directory not found at {ravdess_root_dir}\")\n",
    "\n",
    "if os.path.exists(tess_root_dir):\n",
    "    for subdir, _, files in os.walk(tess_root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                try:\n",
    "                    filename_lower = file.lower()\n",
    "                    emotion = next(em for key, em in tess_emotion_map.items() if key in filename_lower)\n",
    "                    filepath = os.path.join(subdir, file)\n",
    "                    all_data.append((filepath, emotion, 'TESS'))\n",
    "                except StopIteration:\n",
    "                    continue\n",
    "else:\n",
    "    print(f\"Warning: TESS directory not found at {tess_root_dir}\")\n",
    "\n",
    "df = pd.DataFrame(all_data, columns=[\"path\", \"emotion\", \"dataset\"])\n",
    "df = df[df['emotion'] != 'calm'].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nRebalancing datasets to address performance disparity...\")\n",
    "ravdess_df = df[df['dataset'] == 'RAVDESS']\n",
    "tess_df = df[df['dataset'] == 'TESS']\n",
    "tess_df_sampled = tess_df.sample(n=len(ravdess_df), random_state=42)\n",
    "balanced_df = pd.concat([ravdess_df, tess_df_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def add_noise(y, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(y))\n",
    "    return (y + noise * noise_factor).astype(np.float32)\n",
    "\n",
    "def pitch_shift(y, sr, n_steps=3):\n",
    "    return librosa.effects.pitch_shift(y=y, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def time_stretch(y, rate=0.9):\n",
    "    return librosa.effects.time_stretch(y=y, rate=rate)\n",
    "\n",
    "def spec_augment(spec, time_masking_para=40, freq_masking_para=30, num_masks=1):\n",
    "    spec_copy = spec.copy()\n",
    "    n_mels, n_steps = spec_copy.shape\n",
    "    for _ in range(num_masks):\n",
    "        f = random.randrange(0, freq_masking_para)\n",
    "        f0 = random.randrange(0, n_mels - f)\n",
    "        if f > 0:\n",
    "            spec_copy[f0:f0+f, :] = 0\n",
    "        t = random.randrange(0, time_masking_para)\n",
    "        t0 = random.randrange(0, n_steps - t)\n",
    "        if t > 0:\n",
    "            spec_copy[:, t0:t0+t] = 0\n",
    "    return spec_copy\n",
    "\n",
    "def extract_features_robust(y, sr, n_mels=128, n_mfcc=40, max_len=250):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmin=20)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max, top_db=80)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if np.std(mfcc) < 1e-5:\n",
    "        return None\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    features = np.vstack((log_mel, mfcc, mfcc_delta, mfcc_delta2))\n",
    "    if features.shape[1] < max_len:\n",
    "        features = np.pad(features, ((0, 0), (0, max_len - features.shape[1])), mode='constant')\n",
    "    else:\n",
    "        features = features[:, :max_len]\n",
    "    features = (features - np.mean(features)) / (np.std(features) + 1e-6)\n",
    "    if np.isnan(features).any() or np.isinf(features).any():\n",
    "        return None\n",
    "    return features\n",
    "\n",
    "le = LabelEncoder()\n",
    "balanced_df['emotion_encoded'] = le.fit_transform(balanced_df['emotion'])\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['emotion']\n",
    ")\n",
    "\n",
    "def process_data(df, augment=False):\n",
    "    X, y = [], []\n",
    "    SR = 16000\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            y_audio, _ = librosa.load(row['path'], sr=SR)\n",
    "            if len(y_audio) < 400:\n",
    "                continue\n",
    "            audios_to_process = [y_audio]\n",
    "            if augment:\n",
    "                audios_to_process.extend([\n",
    "                    add_noise(y_audio),\n",
    "                    pitch_shift(y_audio, SR),\n",
    "                    time_stretch(y_audio)\n",
    "                ])\n",
    "            for audio in audios_to_process:\n",
    "                features = extract_features_robust(audio, SR)\n",
    "                if features is not None:\n",
    "                    if augment and audio is not y_audio:\n",
    "                        features = spec_augment(features)\n",
    "                    X.append(features)\n",
    "                    y.append(row['emotion_encoded'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['path']}: {e}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"Processing training data (with augmentation)...\")\n",
    "X_train, y_train = process_data(train_df, augment=True)\n",
    "\n",
    "print(\"\\nProcessing testing data (no augmentation)...\")\n",
    "X_test, y_test = process_data(test_df, augment=False)\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "if X_train.size == 0 or X_test.size == 0:\n",
    "    raise ValueError(\"Training or testing data is empty. Please check data processing pipeline.\")\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    def build_model(input_shape, num_classes):\n",
    "        inp = Input(shape=input_shape)\n",
    "        l2_strength = 0.005\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(l2_strength))(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 3))(x)\n",
    "        x = Dropout(0.35)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(256, activation='relu', kernel_regularizer=l2(l2_strength))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(num_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        optimizer = Adam(learning_rate=0.0005)\n",
    "        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = build_model(X_train.shape[1:], len(le.classes_))\n",
    "\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "checkpoint = ModelCheckpoint(\"best_model_balanced.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "model.load_weights(\"best_model_balanced.keras\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "test_df_reset = test_df.reset_index(drop=True)\n",
    "pred_df = test_df_reset.copy()\n",
    "pred_df['pred_emotion_encoded'] = y_pred\n",
    "pred_df['correct'] = pred_df['emotion_encoded'] == pred_df['pred_emotion_encoded']\n",
    "dataset_accuracy = pred_df.groupby('dataset')['correct'].mean()\n",
    "print(dataset_accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix (Balanced Dataset)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Final Model Evaluation on Test Set (using best saved weights) ---\n",
    "\n",
    "Overall Test Loss: 0.7289\n",
    "\n",
    "Overall Test Accuracy: 91.02%16/16 ━━━━━━━━━━━━━━━━━━━━ 2s 109ms/step\n",
    "\n",
    "Classification Report (Overall):\n",
    "\n",
    "precision recall f1-score support\n",
    "\n",
    "\n",
    "\n",
    "angry 0.99 0.96 0.97 76\n",
    "\n",
    "disgust 0.92 0.92 0.92 78\n",
    "\n",
    "fearful 0.93 0.86 0.90 74\n",
    "\n",
    "happy 0.87 0.93 0.90 73\n",
    "\n",
    "neutral 0.96 0.93 0.94 54\n",
    "\n",
    "sad 0.82 0.94 0.88 72\n",
    "\n",
    "surprised 0.97 0.88 0.92 73\n",
    "\n",
    "\n",
    "\n",
    "accuracy 0.92 500\n",
    "\n",
    "macro avg 0.92 0.92 0.92 500\n",
    "\n",
    "weighted avg 0.92 0.92 0.92 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "--- HONEST PERFORMANCE METRICS (Per-Dataset Accuracy) ---\n",
    "\n",
    "dataset\n",
    "\n",
    "RAVDESS 0.846154\n",
    "\n",
    "TESS 0.995833"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 316368,
     "sourceId": 639622,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7591150,
     "sourceId": 12060654,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
